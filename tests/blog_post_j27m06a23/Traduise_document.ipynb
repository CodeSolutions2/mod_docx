{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03449341",
   "metadata": {},
   "source": [
    "# Automatic translation of Resume with Azure, GCP, docx, and mod_docx!\n",
    "\n",
    "Have you ever wanted to automatically change the language on your CV?  There are built-in document changing services on Google Sheets, but they often require you to pay money or create an account. \n",
    "\n",
    "In this post, I create a quick application using Azure Cognitive Services and GCP, and review some XML basics to resave the docx file.\n",
    "\n",
    "![alt text](splash_mod_docx.png)\n",
    "\n",
    "\n",
    "Blog article: https://medium.com/@j622amilah/publishing-code-on-pypi-mod-docx-xml-document-manipulation-f5e89efaf1bc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c39e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PyPI repository \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sudo pip install mod_docx --upgrade\n",
    "# https://pypi.org/project/mod-docx/\n",
    "sys.path.insert(1, '/usr/lib/python3.11/site-packages')\n",
    "import mod_docx\n",
    "\n",
    "# https://pypi.org/project/docx/\n",
    "sys.path.insert(1, '/usr/lib/python3.10/site-packages')\n",
    "import docx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c2bde",
   "metadata": {},
   "source": [
    "# [Step 0] Open the docx file as an XML object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837ad96b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtenir le fichier docx originale\n",
    "fpath = \"../git2/mod_docx/tests\"\n",
    "fichier = \"test_document.docx\"\n",
    "fichier = \"test_complicated_document.docx\"\n",
    "docx_filename = os.path.join(fpath, fichier)\n",
    "        \n",
    "# Create a class object for the name_of_file.class_name. Use the class object, to call the functions in the class.\n",
    "md = mod_docx.mod_docx(docx_filename)\n",
    "\n",
    "# Convert the orignal docx file to XML\n",
    "document_org = md.opendocx(docx_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381ad31",
   "metadata": {},
   "source": [
    "# [Step 1] Modify the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0562627b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_org:  ['Jamilah FOUCHER', 'DATA SCIENTIST', 'Adresse', 'Téléphone', 'Email', 'Linked-In : Nom de profile (4 badges de compétences)', 'Data Science Blog: medium.com/@j622amilah', 'GitHub: github.com/j622amilah', 'ResearchGate: Nom de profile', 'Publications: Nom de profile', \"Je suis intéressé à être un Data Scientist; Je développe actuellement des compétences de spécialiste des données et d'architecte de données pour travailler avec des modèles sur le cloud.\", 'SKILLS', 'Processus de la science des données', 'Poser des questions, Hypothèse, Expérimenter, Analyser (Sélection et réduction des marqueurs, sélection du modèle (Python SDK: mobilenet, OpenAI, Hugging Face), modèle entraînement, flux de travail), Interpréter les résultats, Communiquer et livrer les résultats', 'Apprentissage automatique et profond ', \"méthodes ML en utilisant les algorithmes d'optimisation et l'arbre de décision, méthodes DL en utilisant les algorithmes d'optimisation, RNN, CNN, GANS, Transformer\", 'Types de données traitées', 'Série temporelle, texte, image, son, données statiques et continues', 'Théorie du contrôle, l’identification de systèmes, statistiques', 'n4sid, ARX, créé un modèle prédictif de z-score', 'PROGRAMMING', 'Python: (numpy, scipy, scikit-learn, keras tensorflow, pytorch, pandas, nltk, spacy, pyspark), SQL, Databricks, Azure/GCP/IBM cloud,  MATLAB / Simulink, Excel, VBA, C++, C# (Unity),  Labview, Java, R, Google Apps Scripts, Javascript, HTML, bash', 'VISUALISATION', 'Power BI, Tableau, Streamlit, Google/ Microsoft/ Libreoffice, plotly, matplotlib, seaborn, LaTeX', 'ADDITIONNEL', 'Français permit B', 'Langue (Anglais natif, Français C1 DALF, Japonais niveau 5)', 'ÉDUCATION', \"BAC+8 (PhD) en Ingénierie Mécanique programme d'analyse numérique IGERT NSF  (2005 – 2012)\", 'Ecole DEF, Pays HIJ', 'BAC+5 (MS) Ingénierie Mécanique / pas de degré (2003 – 2004)', 'Transféré à Ecole DEF - Ecole OPQ, Pays HIJ', 'BAC+3 (BS) Electrical Engineering (1999 – 2003)', 'Ecole TUV, Pays HIJ', 'Data Analysts confirmé (2023) : Certificat (numéro de confirmation)', 'Data Scientist confirmé (2022-2023): Certificat (numéro de confirmation)', 'Data Science certificates (2020-2023): Certificat (numéro de confirmation) ', 'EXPÉRIENCE PROFESSIONNELLE', 'Travail 2 (09/2022 – 12/2022)', 'Enterprise ABC, Lyon, Pays LMN.', 'Master Data Management', 'Webscrapping de données à l’aide d’API Benchling en python; créé une classe qui réorganise des données unstructrué.', 'Classification des donnés continu en Java', 'Utilisé l’apprentissage par renforcement (Q-learning) avec Weka pour \\u200b améliorer une algorithme Java EdgeSimCloud qui mesure le trafic réseau', 'Travail 1 (03/2016 – 03/2020)', 'Enterprise DEF, Pays QRS', 'De la prédiction de la désorientation spatiale (DS)', 'Effectué une analyse de cohorte en utilisant d’analyses textuelles NLP. Crée des flux de travail permettant de créer efficacement des expériences, pour un simulateur de mouvement robotique utilisant la réalité virtuelle (VR). Classifié de la perception de la DS mesurant le mouvement de la main, rédigé 3 articles scientifiques.', 'Travail 0 (08/2012 – 06/2015)', 'Enterprise RGB, Pays XYZ', 'De la prédiction des artefacts d’EEG', 'Collecté des données EEG et NIRS humaines dans un environnement quotidien (BMI maison intelligente). Classifié des comportements et des artefacts comme la respiration, le clinquant, la parlant; présenté une démonstration et rédigé 1 rédaction scientifique.', 'De la prédiction du stress & confort', 'Classifié la stress/confort pendant la conduite en fauteuil roulant en utilisant des mesures EEG et conductance cutanée, rédigé 3 articles scientifiques. Brevet obtenu.']\n"
     ]
    }
   ],
   "source": [
    "# Extract text from docx file\n",
    "\n",
    "# Way 0: Form recognizer\n",
    "# However this way the text will not be aligned by line or position within the document.\n",
    "# This could be a problem when trying to automatically replace pieces of text that are equivalent to \n",
    "# other pieces of text (ie: automatic text translation).\n",
    "\n",
    "# Way 1: docx text extraction from the html tags <body> to <\\body>\n",
    "text_org = docx.getdocumenttext(document_org)\n",
    "print('text_org: ', text_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4043f4d",
   "metadata": {},
   "source": [
    " ## Translate the extracted text using Azure and/or GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc6493",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a485b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create resources on Azure : see https://github.com/DevopsPractice7/mod_docx under tests\n",
    "os.system(\"./create_Azure_resources.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduction_Xlang_a_Ylang(de_lang, a_lang, key, endpoint, location, text):\n",
    "    import requests, uuid, json\n",
    "    \n",
    "    constructed_url = endpoint + '/translate'\n",
    "\n",
    "    params = {'api-version': '3.0', 'from': de_lang, 'to': a_lang}\n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "        'Ocp-Apim-Subscription-Region': location,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "    \n",
    "    body = [{'text': f'{text}'}]\n",
    "\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_lang = 'fr'\n",
    "a_lang = ['en']\n",
    "key =  ''\n",
    "endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "location = \"francecentral\"\n",
    "\n",
    "# Keep the line order/position with respect to the docx file, by translating each line \n",
    "text_mod = []\n",
    "for ind, pline in enumerate(text_org):\n",
    "    response = traduction_Xlang_a_Ylang(de_lang, a_lang, key, endpoint, location, pline)\n",
    "    transtext = response[0]['translations'][0]['text'].split(\"\\\\n\")\n",
    "    text_mod.append(transtext[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd6aba",
   "metadata": {},
   "source": [
    "## Google Cloud Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66463db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID :  traductionapi-0\n"
     ]
    }
   ],
   "source": [
    "from os import environ\n",
    "\n",
    "PROJECT_ID = environ.get(\"PROJECT_ID\", \"traductionapi-0\")\n",
    "global PROJECT_ID\n",
    "print('PROJECT_ID : ', PROJECT_ID)\n",
    "\n",
    "\n",
    "LOCATION = \"europe-west9\"\n",
    "\n",
    "# Credentials\n",
    "import os\n",
    "\n",
    "# https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev\n",
    "# In the command line : gcloud auth application-default login\n",
    "# It creates the application_default_credentials.json file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/oem2/.config/gcloud/application_default_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fb6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(target, text):\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    import six\n",
    "    \n",
    "    # https://cloud.google.com/translate/docs/reference/libraries/v2/python\n",
    "    # Be sure to install: sudo pip install google-cloud-translate==2.0.1\n",
    "    # \n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    #if isinstance(text, six.binary_type):\n",
    "    #    text = text.decode(\"utf-8\")\n",
    "        \n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "    \n",
    "    # print(u\"Text: {}\".format(result[\"input\"]))\n",
    "    # print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "    \n",
    "    return result[\"translatedText\"] #u\"Translation: {}\".format(result[\"translatedText\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bca0746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_mod:  ['Jamilah footer', 'DATA SCIENTIST', 'Address', 'Phone', 'Email', 'Linked-In: Profile name (4 skill badges)', 'Data Science Blog: medium.com/@j622amilah', 'GitHub: github.com/j622amilah', 'ResearchGate: Nom de profile', 'Posts: Profile name', 'I am interested in being a Data Scientist; I am currently developing data scientist and data architect skills to work with models on the cloud.', 'SKILLS', 'Data science process', 'Ask questions, Hypothesize, Experiment, Analyze (Marker selection and reduction, model selection (Python SDK: mobilenet, OpenAI, Hugging Face), model training, workflow), Interpret results, Communicate and deliver results', 'Automatic and deep learning', 'ML methods using optimization algorithms and decision tree, DL methods using optimization algorithms, RNN, CNN, GANS, Transformer', 'Types of data processed', 'Time series, text, image, sound, static and continuous data', 'Control theory, system identification, statistics', 'n4sid, ARX, created a predictive z-score model', 'PROGRAMMING', 'Python: (numpy, scipy, scikit-learn, keras tensorflow, pytorch, pandas, nltk, spacy, pyspark), SQL, Databricks, Azure/GCP/IBM cloud,  MATLAB / Simulink, Excel, VBA, C++, C# (Unity),  Labview, Java, R, Google Apps Scripts, Javascript, HTML, bash', 'VISUALISATION', 'Power BI, Tableau, Streamlit, Google/ Microsoft/ Libreoffice, plotly, matplotlib, seaborn, LaTeX', 'ADDITIONAL', 'French permit B', 'Language (native English, French C1 DALF, Japanese level 5)', 'EDUCATION', 'BAC+8 (PhD) in Mechanical Engineering IGERT NSF numerical analysis program (2005 – 2012)', 'Ecole DEF, Pays HE', 'BAC+5 (MS) Mechanical Engineering / no degree (2003 – 2004)', 'Transferred to DEF School - OPQ School, HIJ Country', 'BAC+3 (BS) Electrical Engineering (1999 – 2003)', 'Ecole TUV, Pays HE', 'Confirmed Data Analysts (2023): Certificate (confirmation number)', 'Confirmed Data Scientist (2022-2023): Certificate (confirmation number)', 'Data Science certificates (2020-2023): Certificate (confirmation number)', 'PROFESSIONAL EXPERIENCE', 'Labor 2 (09/2022 – 12/2022)', 'Enterprise ABC, Lyon, Pays LMN.', 'Master Data Management', 'Webscrapping of data using Benchling APIs in python; created a class that reorganizes unstructured data.', 'Continuous Data Classification in Java', 'Used reinforcement learning (Q-learning) with Weka to improve a Java EdgeSimCloud algorithm that measures network traffic', 'Labor 1 (03/2016 – 03/2020)', 'Enterprise DEF, Pays QRS', 'From the prediction of spatial disorientation (SD)', 'Performed a cohort analysis using NLP textual analyses. Creates workflows for efficiently creating experiences, for a robotic motion simulator using virtual reality (VR). Classified of the perception of the DS measuring the movement of the hand, authored 3 scientific articles.', 'Work 0 (08/2012 – 06/2015)', 'Enterprise RGB, Pays XYZ', 'From the prediction of EEG artifacts', 'Collected human EEG and NIRS data in everyday environment (smart home BMI). Classified behaviors and artifacts like breathing, tinsel, talking; presented a demonstration and wrote 1 scientific essay.', 'Stress &amp; comfort prediction', 'Classified stress/comfort during wheelchair driving using EEG and skin conductance measurements, wrote 3 scientific articles. Patent obtained.']\n"
     ]
    }
   ],
   "source": [
    "target = 'en'\n",
    "\n",
    "# Keep the line order/position with respect to the docx file, by translating each line \n",
    "text_mod = []\n",
    "for ind, pline in enumerate(text_org):\n",
    "    textout = translate_text(target, pline)\n",
    "    \n",
    "    # Clean text \n",
    "    replace_le = ['&#39;', '\\xa0']\n",
    "    replace_avec = [\"'\", ' ']\n",
    "    for ind, i in enumerate(replace_le):\n",
    "        textout = textout.replace(i, replace_avec[ind])\n",
    "\n",
    "    # Save cleaned text\n",
    "    text_mod.append(textout)\n",
    "print('text_mod: ', text_mod)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221ca2e",
   "metadata": {},
   "source": [
    "## Replace the text in the open XML object doc_finale, using the docx replace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e72915",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, pline in enumerate(text_org):\n",
    "    \n",
    "    # Le mot qu'on veut chercher\n",
    "    search = pline\n",
    "    print('search:', search)\n",
    "    \n",
    "    # Le mot qu'on veut replacer\n",
    "    replace = text_mod[ind]\n",
    "    print('replace:', replace)\n",
    "    \n",
    "    try:\n",
    "        doc_finale = docx.replace(document_org, search, replace)\n",
    "    except Exception as err:\n",
    "        print('err:', err)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c8b63",
   "metadata": {},
   "source": [
    "# [Step 2] Save the changed XML document as a docx file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = f'{fpath}/'\n",
    "desired_output_docx_name = 'test_document_out.docx'\n",
    "md.savedocx_ver_fichier(docx_filename, root_dir, desired_output_docx_name, doc_finale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02d016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
